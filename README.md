# ğŸ§¾ LedgerX â€“ Fatura MLOps Data Pipeline  
#### **AI-powered invoice (Fatura) ingestion, validation, testing, versioning & automation using Apache Airflow + DVC**

---

## ğŸ“Œ Overview
LedgerX (Fatura Edition) is a production-grade **MLOps pipeline** for invoice OCR data processing.  
The system automates:

- **Data acquisition** (Fatura images â†’ OCR output)
- **Preprocessing/cleaning**
- **Schema validation**
- **Unit testing for reliability**
- **Bias checking**
- **Data versioning with DVC**
- **Report generation**
- **End-to-end orchestration via Airflow**

This repository implements the **IE7305 â€“ MLOps Data Pipeline Submission** requirements and serves as the foundation of the larger LedgerX invoice intelligence platform.

---

## ğŸš€ Key Features (Aligned to MLOps Guidelines)
- **Automated OCR ingestion** for Fatura datasets  
- **Preprocessing**: normalization, cleaning, text extraction  
- **Data validation** using Great Expectations/schema checks  
- **Unit tests** (pytest) for transformations & workflows  
- **Bias detection** using slice-based analysis  
- **DVC tracking** (`raw`, `processed`)  
- **Airflow DAG orchestration** for full workflow automation  
- **Logs + reports** stored locally for reproducibility  
- **Containerized environment** using Docker Compose (Airflow ready)

---

## ğŸ“ Repository Structure
```
ledgerx-mlops-final/
â”‚
â”œâ”€â”€ .dvc/                         # DVC internal metadata
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ ledgerx_fatura_pipeline.py
â”‚   â””â”€â”€ ledgerx_fatura_preprocess.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw OCR inputs/placeholder
â”‚   â”‚   â””â”€â”€ FATURA/               # Raw invoice or OCR source files
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                # Outputs from transformations
â”‚   â”‚   â”œâ”€â”€ fatura_structured.csv
â”‚   â”‚   â””â”€â”€ fatura_cleaned.csv
â”‚   â”‚
â”‚   â””â”€â”€ reports/                  # Pipeline output reports
â”‚       â”œâ”€â”€ schema_check.txt
â”‚       â”œâ”€â”€ bias_check_summary.txt
â”‚       â”œâ”€â”€ test_report.txt
â”‚       â””â”€â”€ summary_report.txt
â”‚
â”œâ”€â”€ reports/                      # (Repo-level logs, optional)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ stages/                   # Pipeline stage scripts (12 total)
â”‚   â”‚   â”œâ”€â”€ acquire_fatura_data.py
â”‚   â”‚   â”œâ”€â”€ data_acquisition_fatura.py
â”‚   â”‚   â”œâ”€â”€ preprocess_fatura.py
â”‚   â”‚   â”œâ”€â”€ preprocess_fatura_to_schema.py
â”‚   â”‚   â”œâ”€â”€ transform_ocr_to_structured.py
â”‚   â”‚   â”œâ”€â”€ clean_fatura_data.py
â”‚   â”‚   â”œâ”€â”€ run_great_expectations.py
â”‚   â”‚   â”œâ”€â”€ validate_schema.py
â”‚   â”‚   â”œâ”€â”€ schema_check.py
â”‚   â”‚   â”œâ”€â”€ bias_check.py
â”‚   â”‚   â”œâ”€â”€ validate_fatura.py
â”‚   â”‚   â””â”€â”€ generate_summary.py
â”‚   â”‚
â”‚   â”œâ”€â”€ reporting/
â”‚   â”‚   â””â”€â”€ generate_summary_report.py     # Final summary used by DAG
â”‚   â”‚
â”‚   â””â”€â”€ validation/
â”‚       â””â”€â”€ run_great_expectations.py      # Duplicate GE script (kept for folder structure)
â”‚
â”œâ”€â”€ tests/                        # Unit tests
â”‚   â”œâ”€â”€ test_preprocess_fatura.py
â”‚   â””â”€â”€ test_validate_fatura.py
â”‚
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ Dockerfile                    # Airflow custom image
â”œâ”€â”€ docker-compose.yml            # Complete Airflow environment
â”‚
â”œâ”€â”€ start_ledgerx.sh              # Entrypoint for Airflow webserver/scheduler
â”‚
â”œâ”€â”€ upload_to_drive.py            # (Optional) Google Drive sync utility
â”œâ”€â”€ drive_auth.py                 # (Optional) Drive auth helper
â”œâ”€â”€ settings.yaml                 # PyDrive config
â”‚
â”œâ”€â”€ dvc.yaml                      # DVC pipeline definition
â”œâ”€â”€ dvc.lock                      # DVC lockfile (data reproducibility)
â”‚
â”œâ”€â”€ pytest.ini                    # Pytest config
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Environment Setup

### **1ï¸âƒ£ Clone the repository**
```
git clone https://github.com/Lochan9/ledgerx-mlops-final.git
cd ledgerx-mlops-final
```

### **2ï¸âƒ£ Create virtual environment**
```
python -m venv .venv
. .venv/Scripts/activate
pip install -r requirements.txt
```

### **3ï¸âƒ£ Install DVC**
```
pip install dvc
```

### **4ï¸âƒ£ Initialize DVC**
```
dvc init
```

---

## ğŸ³ Running Airflow (Docker)
This project includes a **ready-to-run** Airflow Docker environment.

### **1ï¸âƒ£ Start Airflow**
```
docker compose up --build
```

### **2ï¸âƒ£ Access Airflow UI**  
Open browser â†’ **http://localhost:8081**

### **3ï¸âƒ£ Locate your DAG**  
Search for: **ledgerx_fatura_pipeline**

Enable â†’ Trigger DAG

---

## ğŸ” Pipeline Flow (Airflow DAG)
The pipeline follows the required academic MLOps flow:

1. **Acquire Data**  
   `acquire_fatura_data.py` loads the OCR dataset.

2. **Skip Preprocessing (OCR already processed)**  
   For Fatura, preprocessing is minimal.

3. **Schema Validation**  
   Checks formatting, columns, missing values.

4. **Unit Tests**  
   Pytest runs all tests under `/tests`.

5. **DVC Versioning**  
   Creates `.dvc` files for processed data.

6. **Bias Detection**  
   Splits by slices and evaluates fairness.

7. **Generate Reports**  
   Output stored in `/reports`:
   - `schema_check.txt`
   - `test_report.txt`
   - `bias_check_summary.txt`
   - `summary_report.txt`

---

## ğŸ“Š Running Each Component Manually (Optional)

### **1ï¸âƒ£ Acquire**
```
python src/acquire_fatura_data.py
```

### **2ï¸âƒ£ Preprocess**
```
python src/preprocess_fatura.py
```

### **3ï¸âƒ£ Schema Validation**
```
python src/validate_schema.py
```

### **4ï¸âƒ£ Unit Tests**
```
pytest -q
```

### **5ï¸âƒ£ Bias Check**
```
python src/bias_check.py
```

### **6ï¸âƒ£ Report Generation**
```
python src/generate_report.py
```

### **7ï¸âƒ£ Track data with DVC**
```
dvc add data/processed/fatura_ocr.csv
git add data/processed/fatura_ocr.csv.dvc
git commit -m "Versioned processed data"
```

---

## ğŸ“˜ Logs & Where to Find Them
Logs are automatically generated inside the container:

```
/opt/airflow/logs/<dag_id>/<task_id>/
```

To view logs locally:
```
docker logs ledgerx-airflow
```

Reports are saved locally:
```
data/reports/
```

Expected files:
- `schema_check.txt`
- `test_report.txt`
- `bias_check_summary.txt`
- `summary_report.txt`

---

## ğŸ“‘ Deliverables Covered (Matches IE7305 Guidelines)
âœ” Data acquisition  
âœ” Preprocessing  
âœ” Schema validation  
âœ” Unit tests  
âœ” Bias detection (slice-based)  
âœ” Airflow DAG orchestration  
âœ” DVC versioning  
âœ” Logging + report generation  
âœ” Clean professional documentation  

---

## ğŸ§ª Testing
Run all tests:
```
pytest
```

Specific test:
```
pytest tests/test_preprocess.py
```

---

## ğŸ“¦ DVC Workflow
Check status:
```
dvc status
```

Push to remote (if configured):
```
dvc push
```

Pull versions:
```
dvc pull
```

---

## ğŸ§  Project Summary
This repository implements a **full MLOps data pipeline** tailored for the **Fatura invoice OCR dataset** and satisfies the complete academic submission requirements:

- Reproducible  
- Automated  
- Versioned  
- Validated  
- Tested  
- Orchestrated  

This will serve as the foundation for the **Stage-3 Model Pipeline** and **Stage-4 Deployment** phases.

---

## ğŸ‘¥ Contributors
- Lochan Enugula  
- Team LedgerX  

---

## ğŸ“„ License
This project is for academic use under the IE7305 MLOps course guidelines.

